{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-28T10:40:24.494158Z",
     "iopub.status.busy": "2025-03-28T10:40:24.49387Z",
     "iopub.status.idle": "2025-03-28T10:40:24.49898Z",
     "shell.execute_reply": "2025-03-28T10:40:24.498248Z",
     "shell.execute_reply.started": "2025-03-28T10:40:24.494136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:40:25.636147Z",
     "iopub.status.busy": "2025-03-28T10:40:25.635805Z",
     "iopub.status.idle": "2025-03-28T10:40:25.640659Z",
     "shell.execute_reply": "2025-03-28T10:40:25.639665Z",
     "shell.execute_reply.started": "2025-03-28T10:40:25.636117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "train_dir = os.path.join(data_dir, 'train/train')\n",
    "test_dir = os.path.join(data_dir, 'test/test')\n",
    "train_list_file = os.path.join(data_dir, 'train_list.txt')\n",
    "test_list_file = os.path.join(data_dir, 'test_list.txt')\n",
    "output_dir = os.getcwd()\n",
    "results_dir = os.path.join(output_dir, 'results')\n",
    "predictions_dir = os.path.join(output_dir, 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:40:27.156297Z",
     "iopub.status.busy": "2025-03-28T10:40:27.156024Z",
     "iopub.status.idle": "2025-03-28T10:40:27.160475Z",
     "shell.execute_reply": "2025-03-28T10:40:27.159599Z",
     "shell.execute_reply.started": "2025-03-28T10:40:27.156275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "INPUT_SIZE = (426, 560)\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:40:29.023774Z",
     "iopub.status.busy": "2025-03-28T10:40:29.023484Z",
     "iopub.status.idle": "2025-03-28T10:40:29.028557Z",
     "shell.execute_reply": "2025-03-28T10:40:29.027611Z",
     "shell.execute_reply.started": "2025-03-28T10:40:29.02375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def target_transform(depth):\n",
    "    # Resize the depth map to match input size\n",
    "    depth = torch.nn.functional.interpolate(\n",
    "        depth.unsqueeze(0).unsqueeze(0), \n",
    "        size=INPUT_SIZE, \n",
    "        mode='bilinear', \n",
    "        align_corners=True\n",
    "    ).squeeze()\n",
    "    \n",
    "    # Add channel dimension to match model output\n",
    "    depth = depth.unsqueeze(0)\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:40:44.733062Z",
     "iopub.status.busy": "2025-03-28T10:40:44.732739Z",
     "iopub.status.idle": "2025-03-28T10:40:44.74124Z",
     "shell.execute_reply": "2025-03-28T10:40:44.740231Z",
     "shell.execute_reply.started": "2025-03-28T10:40:44.73304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, data_dir, list_file, transform=None, target_transform=None, has_gt=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.has_gt = has_gt\n",
    "        \n",
    "        # Read file list\n",
    "        with open(list_file, 'r') as f:\n",
    "            if has_gt:\n",
    "                self.file_pairs = [line.strip().split() for line in f]\n",
    "            else:\n",
    "                # For test set without ground truth\n",
    "                self.file_list = [line.strip() for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_pairs if self.has_gt else self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_gt:\n",
    "            rgb_path = os.path.join(self.data_dir, self.file_pairs[idx][0])\n",
    "            depth_path = os.path.join(self.data_dir, self.file_pairs[idx][1])\n",
    "            \n",
    "            # Load RGB image\n",
    "            rgb = Image.open(rgb_path).convert('RGB')\n",
    "            \n",
    "            # Load depth map\n",
    "            depth = np.load(depth_path).astype(np.float32)\n",
    "            depth = torch.from_numpy(depth)\n",
    "            \n",
    "            # Apply transformations\n",
    "            if self.transform:\n",
    "                rgb = self.transform(rgb)\n",
    "            \n",
    "            if self.target_transform:\n",
    "                depth = self.target_transform(depth)\n",
    "            else:\n",
    "                # Add channel dimension if not done by transform\n",
    "                depth = depth.unsqueeze(0)\n",
    "            \n",
    "            return rgb, depth, self.file_pairs[idx][0]  # Return filename for saving predictions\n",
    "        else:\n",
    "            # For test set without ground truth\n",
    "            rgb_path = os.path.join(self.data_dir, self.file_list[idx].split(' ')[0])\n",
    "            \n",
    "            # Load RGB image\n",
    "            rgb = Image.open(rgb_path).convert('RGB')\n",
    "            \n",
    "            # Apply transformations\n",
    "            if self.transform:\n",
    "                rgb = self.transform(rgb)\n",
    "            \n",
    "            return rgb, self.file_list[idx]  # No depth, just return the filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:40:46.088448Z",
     "iopub.status.busy": "2025-03-28T10:40:46.088151Z",
     "iopub.status.idle": "2025-03-28T10:40:46.093796Z",
     "shell.execute_reply": "2025-03-28T10:40:46.093015Z",
     "shell.execute_reply.started": "2025-03-28T10:40:46.08842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:40:47.336272Z",
     "iopub.status.busy": "2025-03-28T10:40:47.335981Z",
     "iopub.status.idle": "2025-03-28T10:40:47.342769Z",
     "shell.execute_reply": "2025-03-28T10:40:47.341692Z",
     "shell.execute_reply.started": "2025-03-28T10:40:47.33625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        \n",
    "        # Encoder blocks\n",
    "        self.enc1 = UNetBlock(3, 64)\n",
    "        self.enc2 = UNetBlock(64, 128)\n",
    "        \n",
    "        # Decoder blocks\n",
    "        self.dec2 = UNetBlock(128 + 64, 64)\n",
    "        self.dec1 = UNetBlock(64, 32)\n",
    "        \n",
    "        # Final layer\n",
    "        self.final = nn.Conv2d(32, 1, kernel_size=1)\n",
    "        \n",
    "        # Pooling and upsampling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        x = self.pool(enc1)\n",
    "        \n",
    "        x = self.enc2(x)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = nn.functional.interpolate(x, size=enc1.shape[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x, enc1], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        x = self.dec1(x)\n",
    "        x = self.final(x)\n",
    "        \n",
    "        # Output non-negative depth values\n",
    "        x = torch.sigmoid(x)*10\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:45:31.794688Z",
     "iopub.status.busy": "2025-03-28T10:45:31.794304Z",
     "iopub.status.idle": "2025-03-28T10:45:31.803941Z",
     "shell.execute_reply": "2025-03-28T10:45:31.802778Z",
     "shell.execute_reply.started": "2025-03-28T10:45:31.794656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"Train the model and save the best based on validation metrics\"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, targets, _ in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets, _ in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "                \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), os.path.join(results_dir, 'best_model.pth'))\n",
    "            print(f\"New best model saved at epoch {epoch+1} with validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest model was from epoch {best_epoch+1} with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(os.path.join(results_dir, 'best_model.pth')))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:45:33.94406Z",
     "iopub.status.busy": "2025-03-28T10:45:33.94372Z",
     "iopub.status.idle": "2025-03-28T10:45:33.957499Z",
     "shell.execute_reply": "2025-03-28T10:45:33.956578Z",
     "shell.execute_reply.started": "2025-03-28T10:45:33.944033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"Evaluate the model and compute metrics on validation set\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    mae = 0.0\n",
    "    rmse = 0.0\n",
    "    rel = 0.0\n",
    "    delta1 = 0.0\n",
    "    delta2 = 0.0\n",
    "    delta3 = 0.0\n",
    "    sirmse = 0.0\n",
    "    \n",
    "    total_samples = 0\n",
    "    target_shape = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, filenames in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "            total_samples += batch_size\n",
    "            \n",
    "            if target_shape is None:\n",
    "                target_shape = targets.shape\n",
    "            \n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Resize outputs to match target dimensions\n",
    "            outputs = nn.functional.interpolate(\n",
    "                outputs,\n",
    "                size=targets.shape[-2:],  # Match height and width of targets\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "            \n",
    "            # Calculate metrics\n",
    "            abs_diff = torch.abs(outputs - targets)\n",
    "            mae += torch.sum(abs_diff).item()\n",
    "            rmse += torch.sum(torch.pow(abs_diff, 2)).item()\n",
    "            rel += torch.sum(abs_diff / (targets + 1e-6)).item()\n",
    "            \n",
    "            # Calculate scale-invariant RMSE for each image in the batch\n",
    "            for i in range(batch_size):\n",
    "                # Convert tensors to numpy arrays\n",
    "                pred_np = outputs[i].cpu().squeeze().numpy()\n",
    "                target_np = targets[i].cpu().squeeze().numpy()\n",
    "                \n",
    "                EPSILON = 1e-6\n",
    "                \n",
    "                valid_target = target_np > EPSILON\n",
    "                if not np.any(valid_target):\n",
    "                    continue\n",
    "                \n",
    "                target_valid = target_np[valid_target]\n",
    "                pred_valid = pred_np[valid_target]\n",
    "                \n",
    "                log_target = np.log(target_valid)\n",
    "                \n",
    "                pred_valid = np.where(pred_valid > EPSILON, pred_valid, EPSILON)\n",
    "                log_pred = np.log(pred_valid)\n",
    "                \n",
    "                # Calculate scale-invariant error\n",
    "                diff = log_pred - log_target\n",
    "                diff_mean = np.mean(diff)\n",
    "                \n",
    "                # Calculate RMSE for this image\n",
    "                sirmse += np.sqrt(np.mean((diff - diff_mean) ** 2))\n",
    "            \n",
    "            # Calculate thresholded accuracy\n",
    "            max_ratio = torch.max(outputs / (targets + 1e-6), targets / (outputs + 1e-6))\n",
    "            delta1 += torch.sum(max_ratio < 1.25).item()\n",
    "            delta2 += torch.sum(max_ratio < 1.25**2).item()\n",
    "            delta3 += torch.sum(max_ratio < 1.25**3).item()\n",
    "            \n",
    "            # Save some sample predictions\n",
    "            if total_samples <= 5 * batch_size:\n",
    "                for i in range(min(batch_size, 5)):\n",
    "                    idx = total_samples - batch_size + i\n",
    "                    \n",
    "                    # Convert tensors to numpy arrays\n",
    "                    input_np = inputs[i].cpu().permute(1, 2, 0).numpy()\n",
    "                    target_np = targets[i].cpu().squeeze().numpy()\n",
    "                    output_np = outputs[i].cpu().squeeze().numpy()\n",
    "                    \n",
    "                    # Normalize for visualization\n",
    "                    input_np = (input_np - input_np.min()) / (input_np.max() - input_np.min() + 1e-6)\n",
    "                    \n",
    "                    # Create visualization\n",
    "                    plt.figure(figsize=(15, 5))\n",
    "                    \n",
    "                    plt.subplot(1, 3, 1)\n",
    "                    plt.imshow(input_np)\n",
    "                    plt.title(\"RGB Input\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(1, 3, 2)\n",
    "                    plt.imshow(target_np, cmap='plasma')\n",
    "                    plt.title(\"Ground Truth Depth\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(1, 3, 3)\n",
    "                    plt.imshow(output_np, cmap='plasma')\n",
    "                    plt.title(\"Predicted Depth\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(results_dir, f\"sample_{idx}.png\"))\n",
    "                    plt.close()\n",
    "            \n",
    "            # Free up memory\n",
    "            del inputs, targets, outputs, abs_diff, max_ratio\n",
    "            \n",
    "        # Clear CUDA cache\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate final metrics using stored target shape\n",
    "    total_pixels = target_shape[1] * target_shape[2] * target_shape[3]  # channels * height * width\n",
    "    mae /= total_samples * total_pixels\n",
    "    rmse = np.sqrt(rmse / (total_samples * total_pixels))\n",
    "    rel /= total_samples * total_pixels\n",
    "    sirmse = sirmse / total_samples\n",
    "    delta1 /= total_samples * total_pixels\n",
    "    delta2 /= total_samples * total_pixels\n",
    "    delta3 /= total_samples * total_pixels\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'siRMSE': sirmse,\n",
    "        'REL': rel,\n",
    "        'Delta1': delta1,\n",
    "        'Delta2': delta2,\n",
    "        'Delta3': delta3\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:45:36.391354Z",
     "iopub.status.busy": "2025-03-28T10:45:36.391034Z",
     "iopub.status.idle": "2025-03-28T10:45:36.39739Z",
     "shell.execute_reply": "2025-03-28T10:45:36.396233Z",
     "shell.execute_reply.started": "2025-03-28T10:45:36.391329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_test_predictions(model, test_loader, device):\n",
    "    \"\"\"Generate predictions for the test set without ground truth\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Ensure predictions directory exists\n",
    "    ensure_dir(predictions_dir)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, filenames in tqdm(test_loader, desc=\"Generating Test Predictions\"):\n",
    "            inputs = inputs.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Resize outputs to match original input dimensions (426x560)\n",
    "            outputs = nn.functional.interpolate(\n",
    "                outputs,\n",
    "                size=(426, 560),  # Original input dimensions\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "            \n",
    "            # Save all test predictions\n",
    "            for i in range(batch_size):\n",
    "                # Get filename without extension\n",
    "                filename = filenames[i].split(' ')[1]\n",
    "                \n",
    "                # Save depth map prediction as numpy array\n",
    "                depth_pred = outputs[i].cpu().squeeze().numpy()\n",
    "                np.save(os.path.join(predictions_dir, f\"{filename}\"), depth_pred)\n",
    "            \n",
    "            # Clean up memory\n",
    "            del inputs, outputs\n",
    "        \n",
    "        # Clear cache after test predictions\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:45:37.986906Z",
     "iopub.status.busy": "2025-03-28T10:45:37.986576Z",
     "iopub.status.idle": "2025-03-28T10:45:37.997319Z",
     "shell.execute_reply": "2025-03-28T10:45:37.996372Z",
     "shell.execute_reply.started": "2025-03-28T10:45:37.986877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Create output directories\n",
    "    ensure_dir(results_dir)\n",
    "    ensure_dir(predictions_dir)\n",
    "    \n",
    "    # Define transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(INPUT_SIZE),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Data augmentation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(INPUT_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create training dataset with ground truth\n",
    "    train_full_dataset = DepthDataset(\n",
    "        data_dir=train_dir,\n",
    "        list_file=train_list_file, \n",
    "        transform=train_transform,\n",
    "        target_transform=target_transform,\n",
    "        has_gt=True\n",
    "    )\n",
    "    \n",
    "    # Create test dataset without ground truth\n",
    "    test_dataset = DepthDataset(\n",
    "        data_dir=test_dir,\n",
    "        list_file=test_list_file,\n",
    "        transform=test_transform,\n",
    "        has_gt=False  # Test set has no ground truth\n",
    "    )\n",
    "    \n",
    "    # Split training dataset into train and validation\n",
    "    total_size = len(train_full_dataset)\n",
    "    train_size = int(0.85 * total_size)  # 85% for training\n",
    "    val_size = total_size - train_size    # 15% for validation\n",
    "    \n",
    "    # Set a fixed random seed for reproducibility\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        train_full_dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    # Create data loaders with memory optimizations\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=NUM_WORKERS, \n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=True,\n",
    "        persistent_workers=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=NUM_WORKERS, \n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=NUM_WORKERS, \n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Clear CUDA cache before model initialization\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Display GPU memory info\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"Initially allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    \n",
    "    model = SimpleUNet()\n",
    "    model = model.to(DEVICE)\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    # Print memory usage after model initialization\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Memory allocated after model init: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, DEVICE)\n",
    "            \n",
    "    # Evaluate the model on validation set\n",
    "    print(\"Evaluating model on validation set...\")\n",
    "    metrics = evaluate_model(model, val_loader, DEVICE)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "    \n",
    "    # Save metrics to file\n",
    "    with open(os.path.join(results_dir, 'validation_metrics.txt'), 'w') as f:\n",
    "        for name, value in metrics.items():\n",
    "            f.write(f\"{name}: {value:.4f}\\n\")\n",
    "    \n",
    "    # Generate predictions for the test set\n",
    "    print(\"Generating predictions for test set...\")\n",
    "    generate_test_predictions(model, test_loader, DEVICE)\n",
    "    \n",
    "    print(f\"Results saved to {results_dir}\")\n",
    "    print(f\"All test depth map predictions saved to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:45:40.286693Z",
     "iopub.status.busy": "2025-03-28T10:45:40.286375Z",
     "iopub.status.idle": "2025-03-28T11:10:22.109679Z",
     "shell.execute_reply": "2025-03-28T11:10:22.108733Z",
     "shell.execute_reply.started": "2025-03-28T10:45:40.286664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 20375, Validation size: 3596, Test size: 650\n",
      "GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "Total GPU memory: 12.88 GB\n",
      "Initially allocated: 0.00 GB\n",
      "Using device: cuda\n",
      "Memory allocated after model init: 0.00 GB\n",
      "Starting training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5093/5093 [28:02<00:00,  3.03it/s]\n",
      "Validation: 100%|██████████| 899/899 [02:36<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2497, Validation Loss: 2.0192\n",
      "New best model saved at epoch 1 with validation loss: 2.0192\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5093/5093 [26:57<00:00,  3.15it/s]\n",
      "Validation: 100%|██████████| 899/899 [02:25<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9382, Validation Loss: 1.8727\n",
      "New best model saved at epoch 2 with validation loss: 1.8727\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5093/5093 [27:34<00:00,  3.08it/s]\n",
      "Validation: 100%|██████████| 899/899 [02:38<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8387, Validation Loss: 1.7996\n",
      "New best model saved at epoch 3 with validation loss: 1.7996\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5093/5093 [28:54<00:00,  2.94it/s]\n",
      "Validation: 100%|██████████| 899/899 [03:14<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7884, Validation Loss: 1.8100\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5093/5093 [28:52<00:00,  2.94it/s]\n",
      "Validation: 100%|██████████| 899/899 [03:23<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7547, Validation Loss: 1.8426\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5093/5093 [24:12<00:00,  3.51it/s]\n",
      "Validation: 100%|██████████| 899/899 [02:18<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7267, Validation Loss: 1.8034\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 3588/5093 [16:07<06:45,  3.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# Evaluate the model on validation set\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating model on validation set...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[39m\n\u001b[32m     26\u001b[39m     loss.backward()\n\u001b[32m     27\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * inputs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     33\u001b[39m train_loss /= \u001b[38;5;28mlen\u001b[39m(train_loader.dataset)\n\u001b[32m     34\u001b[39m train_losses.append(train_loss)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T11:11:42.934709Z",
     "iopub.status.busy": "2025-03-28T11:11:42.934361Z",
     "iopub.status.idle": "2025-03-28T11:11:43.040042Z",
     "shell.execute_reply": "2025-03-28T11:11:43.039142Z",
     "shell.execute_reply.started": "2025-03-28T11:11:42.934677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Open a sample prediction from validation set\n",
    "Image.open('/kaggle/working/results/sample_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# save current model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m torch.save(\u001b[43mmodel\u001b[49m.state_dict(), os.path.join(results_dir, \u001b[33m'\u001b[39m\u001b[33mcurrent_model.pth\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# save current model\n",
    "torch.save(model.state_dict(), os.path.join(results_dir, 'current_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11588651,
     "sourceId": 96682,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
